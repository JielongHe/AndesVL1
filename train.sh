#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=10
#SBATCH --gpus=4
#SBATCH --partition=gpu_h100
#SBATCH --time=40:00:00
#SBATCH --mem=84G
#SBATCH --exclusive
#SBATCH --job-name=qwen1
#SBATCH -o ./log/qwen_%j.out

# =============== ç”Ÿæˆæ—¶é—´æˆ³ ===============
TIMESTAMP=$(date +"%Y%m%d_%H%M")
LOG_DIR="./log"
OUTPUT_DIR="./check_qwen3/checkpoints_${TIMESTAMP}"



# =============== åŠ è½½ Snellius 2023 å·¥å…·é“¾ + CUDA ===============
module load 2023
module load CUDA/12.4.0

nvidia-smi

if [ -z "$CUDA_HOME" ]; then
    echo "âŒ CUDA_HOME not set after module load!"
    exit 1
fi
echo "âœ… CUDA_HOME = $CUDA_HOME"

# =============== æ¿€æ´» Conda ç¯å¢ƒ ===============
source /home/khe/miniconda3/bin/activate qwen

# =============== è·³è¿‡ DeepSpeed CUDA ç®—å­ç¼–è¯‘ï¼ˆå…³é”®ï¼ï¼‰===============
export DS_SKIP_CUDA_BUILD=1

# =============== ç¯å¢ƒæ£€æŸ¥ï¼ˆç›´æ¥å†…è”ï¼Œé¿å… /tmp é—®é¢˜ï¼‰===============
echo "ğŸ” Checking PyTorch and CUDA..."
python -c "
import torch
print('PyTorch version:', torch.__version__)
print('CUDA available:', torch.cuda.is_available())
print('Number of GPUs:', torch.cuda.device_count())
if not torch.cuda.is_available():
    exit(1)
print('âœ… CUDA check passed.')
"

if [ $? -ne 0 ]; then
    echo "âŒ CUDA check failed!"
    exit 1
fi

# =============== å¯åŠ¨è®­ç»ƒ ===============
MASTER_ADDR="127.0.0.1"
MASTER_PORT=$(shuf -i 20000-29999 -n 1)
NPROC_PER_NODE=4




torchrun --nproc_per_node=$NPROC_PER_NODE train.py \
  --dataset DGM4 \
  --epochs 8 \
  --batch-size 4 \
  --lr 5e-5 \
  --lr-scheduler cosine \
  --warmup-ratio 0.1 \
  --lr-scale 1.5 \
  --regular-weight 0.05 \
  --train-json /home/aorus/He/qwen-vl-finetune/SAMM_data/SAMM-with-CAP/train1.json \
  --val-json /home/aorus/He/qwen-vl-finetune/SAMM_data/SAMM-with-CAP/val.json
